{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprint 4: Build a model for forecasting the number of customers of the merchant\n",
    "\n",
    "### Step 1:  Data generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'order_datetime',\n",
      "       'user_id', 'merchant_abn', 'dollar_value', 'fraud_probability_x',\n",
      "       'fraud_probability_y', 'consumer_id', 'name', 'address', 'state',\n",
      "       'postcode', 'gender', 'year', 'month', 'cpi', 'is_fraud'],\n",
      "      dtype='object')\n",
      "   merchant_abn    dollar_sum\n",
      "0   11149063370  164023.03278\n",
      "   merchant_abn  fraud_probability_x  fraud_probability_y         cpi\n",
      "0   11149063370            51.588733            11.721278  108.877453\n",
      "   merchant_abn state  postcode  gender  is_fraud\n",
      "0   11149063370   NSW      4311  Female      True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('../../project-2-group-buy-now-pay-later-industry-project-4/data/tables/df_new_week8.csv')\n",
    "print(df.columns)\n",
    "df['dollar_value'] = df['dollar_value'].fillna(0)\n",
    "# find number of different consumer_id by group by merchant_abn\n",
    "consumer_count = df.groupby('merchant_abn')['consumer_id'].nunique().reset_index(name='count')\n",
    "# Group other variables are according to merchant_abn\n",
    "def mode_group(group):\n",
    "    modes = {}\n",
    "    for col in group.columns:\n",
    "        if col == 'merchant_abn':\n",
    "            continue\n",
    "        try:\n",
    "            modes[col] = pd.Series.mode(group[col])[0]\n",
    "        except IndexError:\n",
    "            modes[col] = np.nan\n",
    "    return pd.Series(modes)\n",
    "consumer_dsum = df.groupby('merchant_abn')['dollar_value'].sum().reset_index(name='dollar_sum')\n",
    "print(consumer_dsum.head(1))\n",
    "consumer_tmp1 = df.groupby('merchant_abn')[['fraud_probability_x','fraud_probability_y','cpi']].mean().reset_index()\n",
    "print(consumer_tmp1.head(1))\n",
    "consumer_tmp2 = df.groupby('merchant_abn')[['state','postcode','gender','is_fraud']].apply(mode_group).reset_index()\n",
    "print(consumer_tmp2.head(1))\n",
    "# merge them together \n",
    "df_4 = pd.merge(consumer_count,consumer_dsum)\n",
    "df_4 = pd.merge(df_4,consumer_tmp1)\n",
    "df_4 = pd.merge(df_4,consumer_tmp2)\n",
    "df_4.head(2)\n",
    "df_4.to_csv('../../project-2-group-buy-now-pay-later-industry-project-4/data/tables/df_new_week9.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step2: Build a model to predict number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['NSW', 'QLD', 'SA', 'VIC', 'WA'], dtype=object), array(['Female', 'Male'], dtype=object), array([ 800,  850,  881, 1026, 1028, 1132, 1166, 1177, 1229, 1470, 1480,\n",
      "       1835, 2106, 2430, 2582, 2757, 2867, 2869, 3387, 3521, 4311, 4825,\n",
      "       5132, 6718, 7182])]\n",
      "    dollar_sum  fraud_probability_x  fraud_probability_y       cpi  NSW  QLD  \\\n",
      "19   -0.868763            -1.890365             0.014704 -0.166445  0.0  0.0   \n",
      "25   -0.406762            -0.299954            -0.086352 -0.166445  1.0  0.0   \n",
      "\n",
      "     SA  VIC   WA  Female  ...  2757  2867  2869  3387  3521  4311  4825  \\\n",
      "19  1.0  0.0  0.0     0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "25  0.0  0.0  0.0     1.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "    5132  6718  7182  \n",
      "19   1.0   0.0   0.0  \n",
      "25   0.0   0.0   0.0  \n",
      "\n",
      "[2 rows x 36 columns]\n",
      "[-9.84812232e-12  5.05304581e-13 -1.44033260e+02  5.87904897e+00\n",
      "  5.98520578e+01  1.67423467e+02 -6.31304108e+01 -6.62053537e+01\n",
      " -9.62840149e+01 -2.41165148e+01  2.24304428e+01 -2.90868762e+01\n",
      "  2.09362560e+02 -1.61394543e+02 -9.37137912e+01  2.80206746e+02\n",
      " -1.09884724e+02 -9.86600665e+01  1.23754886e+02  2.11269939e+02\n",
      " -6.35286123e+01 -2.09922645e+02 -3.94068430e+01 -1.63351729e-02\n",
      "  1.11146428e+02  1.15781816e-04 -1.28034892e-04  2.69659013e+02\n",
      " -3.41217413e+01  7.39587232e+01  6.53612868e+01 -3.90569139e+02\n",
      " -6.94688501e+01 -6.16690100e+01  1.17593105e+02 -1.01561557e+02]\n"
     ]
    }
   ],
   "source": [
    "# Build a linear regression model to predict the number of customers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ohe = OneHotEncoder()\n",
    "scaler = StandardScaler()\n",
    "X = df_4[['dollar_sum','fraud_probability_x','fraud_probability_y','cpi']]\n",
    "# standardizing the data\n",
    "\n",
    "X = pd.DataFrame(scaler.fit_transform(X),columns=['dollar_sum','fraud_probability_x','fraud_probability_y','cpi'])\n",
    "X_transformed = ohe.fit_transform(df_4[['state','gender','postcode']]).toarray()\n",
    "print(ohe.categories_)\n",
    "c = [str(j) for i in ohe.categories_ for j in i]\n",
    "X_transformed = pd.DataFrame(X_transformed, columns=c)\n",
    "for name in c:\n",
    "    X[name] = list(X_transformed[name])\n",
    "y = df_4['count']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "print(X_train.head(2))\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "print(lm.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 62.76977377010564\n",
      "Mean Squared Error: 7611.28189678359\n",
      "train R-squared: 1.0\n",
      "test R-squared: 0.10934724123301687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "y_tpred = lm.predict(X_train)\n",
    "y_pred = lm.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r2t = r2_score(y_train, y_tpred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"train R-squared: {r2t}\")\n",
    "print(f\"test R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2=1 on the training set indicates a good fit of the model. From the parameter results of linear regression, it can be found that dollar_sum has the greatest impact on the consumer count."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
